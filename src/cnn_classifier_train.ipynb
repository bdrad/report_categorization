{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "import sentence_features\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 120\n",
    "filter_sizes = (3, 5, 7)\n",
    "num_filters = 64\n",
    "dropout_prob = (0.3, 0.4)\n",
    "hidden_dims = 64\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "num_epochs = 8\n",
    "\n",
    "# Prepossessing parameters\n",
    "sequence_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "fastText_path = \"../data/models/fastText/fastText_sw_cbow120.bin\"\n",
    "ft = train_embeddings.load_fastText_model(fastText_path)\n",
    "\n",
    "mapped_reports_path = \"../data/processed/processed_reports/preprocessed_findings_replace_sw\"\n",
    "mapped_reports = pickle.load(open(mapped_reports_path, 'rb'))\n",
    "\n",
    "pipeline = make_pipeline(train_embeddings.FastTextReportVectorizer(ft, granularity=\"word\", pad_len=200), sentence_features.LabelSeparator(), None)\n",
    "data, labels = pipeline.transform(mapped_reports)\n",
    "\n",
    "split_point = int(0.85 * len(data))\n",
    "\n",
    "trainingX = np.array(data[:split_point])\n",
    "trainingY = np.array(labels[:split_point])\n",
    "print(np.unique(trainingY, return_counts=True))\n",
    "\n",
    "testingX = np.array(data[split_point:])\n",
    "testingY = np.array(labels[split_point:])\n",
    "print(np.unique(testingY, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training X shape: \" + str(trainingX.shape))\n",
    "print(\"Training Y shape: \" + str(trainingY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (sequence_length, embedding_dim)\n",
    "\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Dropout(dropout_prob[0])(model_input)\n",
    "\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainingX, trainingY, batch_size=batch_size, epochs=num_epochs, validation_data=(testingX, testingY), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testingX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testingY, predictions, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
