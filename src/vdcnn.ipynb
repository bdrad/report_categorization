{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "import sentence_features\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import pickle\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 250\n",
    "num_convs = [64, 128, 256, 512]\n",
    "hidden_dims = [2048, 1024, 512]\n",
    "sz = 3\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 7\n",
    "\n",
    "# Prepossessing parameters\n",
    "sequence_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "fastText_path = \"../data/models/fastText/fastText_sw_cbow120.bin\"\n",
    "ft = train_embeddings.load_fastText_model(fastText_path)\n",
    "\n",
    "mapped_reports_path = \"../data/processed/processed_reports/preprocessed_findings_replace_sw\"\n",
    "mapped_reports = pickle.load(open(mapped_reports_path, 'rb'))\n",
    "shuffle(mapped_reports)\n",
    "pipeline = make_pipeline(train_embeddings.FastTextReportVectorizer(ft, granularity=\"word\", pad_len=230), sentence_features.LabelSeparator(), None)\n",
    "data, labels = pipeline.transform(mapped_reports)\n",
    "\n",
    "split_point = int(0.85 * len(data))\n",
    "\n",
    "trainingX = np.array(data[:split_point])\n",
    "trainingY = np.array(labels[:split_point])\n",
    "print(np.unique(trainingY, return_counts=True))\n",
    "\n",
    "testingX = np.array(data[split_point:])\n",
    "testingY = np.array(labels[split_point:])\n",
    "print(np.unique(testingY, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training X shape: \" + str(trainingX.shape))\n",
    "print(\"Training Y shape: \" + str(trainingY.shape))\n",
    "print(\"Testing X shape: \" + str(testingX.shape))\n",
    "print(\"Testing Y shape: \" + str(testingX.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (sequence_length, embedding_dim)\n",
    "\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = Convolution1D(filters=64, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(model_input)\n",
    "\n",
    "for nc in num_convs:\n",
    "    z = Convolution1D(filters=nc, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(z)\n",
    "    z = Convolution1D(filters=nc, kernel_size=sz, padding=\"valid\", activation=\"relu\", strides=1)(z)\n",
    "    z = MaxPooling1D(pool_size=2)(z)\n",
    "\n",
    "z = Flatten()(z)\n",
    "    \n",
    "for hd in hidden_dims:\n",
    "    z = Dense(hd, activation=\"relu\")(z)\n",
    "    z = Dropout(0.3)(z)\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.summary()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainingX, trainingY, batch_size=batch_size, epochs=num_epochs, validation_data=(testingX, testingY), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testingX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testingY, predictions, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../data/processed/vdcnn_120.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
